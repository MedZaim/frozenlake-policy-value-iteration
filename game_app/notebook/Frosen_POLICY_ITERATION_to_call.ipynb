{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {"tags": ["parameters"]},
   "outputs": [],
   "source": [
    "# Papermill injected parameters (default values here are placeholders)\n",
    "rows = 5\n",
    "cols = 5\n",
    "start = (0, 0)\n",
    "goal = (4, 4)\n",
    "holes = [(0,3),(1,0),(2,2),(3,0),(3,2)]\n",
    "slippery = False\n",
    "slip_prob = 0.2  # (not used by base gym env)\n",
    "gamma = 0.99\n",
    "theta = 1e-8\n",
    "map_desc = None  # optional list[str] provided by UI\n",
    "current_state = None  # optional flattened index\n",
    "current_row = None  # optional row if current_state not given\n",
    "current_col = None  # optional col if current_state not given\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, time, ast\n",
    "try:\n",
    "    import gymnasium as gym\n",
    "except ImportError:\n",
    "    import gym\n",
    "\n",
    "# --- Normalize potentially stringified parameters ---\n",
    "def _to_tuple_2(x):\n",
    "    if isinstance(x, tuple) and len(x)==2:\n",
    "        return (int(x[0]), int(x[1]))\n",
    "    if isinstance(x, str):\n",
    "        t = ast.literal_eval(x)\n",
    "        return (int(t[0]), int(t[1]))\n",
    "    t = tuple(x)\n",
    "    return (int(t[0]), int(t[1]))\n",
    "\n",
    "def _to_tuple_list(x):\n",
    "    if isinstance(x, str):\n",
    "        v = ast.literal_eval(x)\n",
    "    else:\n",
    "        v = x\n",
    "    return [tuple(map(int,t)) for t in v]\n",
    "\n",
    "start = _to_tuple_2(start)\n",
    "goal = _to_tuple_2(goal)\n",
    "holes = _to_tuple_list(holes)\n",
    "if isinstance(map_desc, str):\n",
    "    map_desc = ast.literal_eval(map_desc)\n",
    "\n",
    "# --- Build map_desc if not supplied ---\n",
    "def build_desc(rows, cols, start, goal, holes):\n",
    "    arr = np.full((rows, cols), 'F', dtype='<U1')\n",
    "    sr, sc = start; gr, gc = goal\n",
    "    arr[sr, sc] = 'S'; arr[gr, gc] = 'G'\n",
    "    for hr, hc in holes: arr[hr, hc] = 'H'\n",
    "    return [''.join(r) for r in arr]\n",
    "\n",
    "if map_desc is None:\n",
    "    map_desc = build_desc(rows, cols, start, goal, holes)\n",
    "\n",
    "# --- Create environment ---\n",
    "env = gym.make(\n",
    "    'FrozenLake-v1',\n",
    "    is_slippery=bool(slippery),\n",
    "    desc=map_desc,\n",
    "    render_mode='human',\n",
    ")\n",
    "\n",
    "# Force starting state\n",
    "env.reset()\n",
    "if current_state is not None:\n",
    "    try: env.unwrapped.s = int(current_state)\n",
    "    except Exception: pass\n",
    "elif (current_row is not None) and (current_col is not None):\n",
    "    try: env.unwrapped.s = int(current_row)*cols + int(current_col)\n",
    "    except Exception: pass\n",
    "else:\n",
    "    try: env.unwrapped.s = start[0]*cols + start[1]\n",
    "    except Exception: pass\n",
    "\n",
    "print(f'Start position in notebook set to index: {env.unwrapped.s}')\n",
    "# Transition model reference\n",
    "P = env.unwrapped.P\n",
    "nS = env.observation_space.n\n",
    "nA = env.action_space.n\n",
    "\n",
    "# --- Policy Iteration Components ---\n",
    "def policy_evaluation(pi, V=None, gamma=gamma, theta=theta):\n",
    "    if V is None: V = np.zeros(nS, dtype=np.float64)\n",
    "    else: V = np.array(V, dtype=np.float64, copy=True)\n",
    "    while True:\n",
    "        delta = 0.0\n",
    "        for s in range(nS):\n",
    "            v_old = V[s]; a = pi[s]; v_new = 0.0\n",
    "            for (prob, ns, r, done) in P[s][a]:\n",
    "                v_new += prob * (r + gamma * (0.0 if done else V[ns]))\n",
    "            V[s] = v_new; delta = max(delta, abs(v_old - v_new))\n",
    "        if delta < theta: break\n",
    "    return V\n",
    "\n",
    "def policy_improvement(V, gamma=gamma):\n",
    "    pi = np.zeros(nS, dtype=int)\n",
    "    for s in range(nS):\n",
    "        q = np.zeros(nA, dtype=np.float64)\n",
    "        for a in range(nA):\n",
    "            for (prob, ns, r, done) in P[s][a]:\n",
    "                q[a] += prob * (r + gamma * (0.0 if done else V[ns]))\n",
    "        pi[s] = int(np.argmax(q))\n",
    "    return pi\n",
    "\n",
    "def policy_iteration(gamma=gamma, theta=theta):\n",
    "    pi = np.random.randint(0, nA, size=nS, dtype=int)\n",
    "    V = np.zeros(nS, dtype=np.float64)\n",
    "    iters = 0\n",
    "    while True:\n",
    "        iters += 1\n",
    "        V = policy_evaluation(pi, V, gamma=gamma, theta=theta)\n",
    "        new_pi = policy_improvement(V, gamma=gamma)\n",
    "        if np.array_equal(pi, new_pi):\n",
    "            pi = new_pi; break\n",
    "        pi = new_pi\n",
    "    return pi, V, iters\n",
    "\n",
    "pi_opt, V_opt, iters = policy_iteration(gamma=gamma, theta=theta)\n",
    "\n",
    "def run_episode(env, pi):\n",
    "    obs, info = env.reset()\n",
    "    if current_state is not None:\n",
    "        try: env.unwrapped.s = int(current_state); obs = env.unwrapped.s\n",
    "        except Exception: pass\n",
    "    elif (current_row is not None) and (current_col is not None):\n",
    "        try: env.unwrapped.s = int(current_row)*cols + int(current_col); obs = env.unwrapped.s\n",
    "        except Exception: pass\n",
    "    terminated = truncated = False; total = 0.0; steps = 0\n",
    "    while not (terminated or truncated):\n",
    "        a = int(pi[obs])\n",
    "        obs, r, terminated, truncated, info = env.step(a)\n",
    "        total += r; steps += 1\n",
    "    return total, steps, terminated, truncated\n",
    "\n",
    "total_reward, steps, terminated, truncated = run_episode(env, pi_opt)\n",
    "print(f'Episode -> reward: {total_reward}, steps: {steps}, terminated: {terminated}, truncated: {truncated}')\n",
    "print(f'Converged in {iters} iterations')\n",
    "side = int(np.sqrt(nS))\n",
    "print('Optimal V (reshaped if square):')\n",
    "if side*side == nS: print(np.round(V_opt.reshape(side, side), 3))\n",
    "else: print(np.round(V_opt, 3))\n",
    "arrow_map = {0:'←',1:'↓',2:'→',3:'↑'}\n",
    "print('\\nOptimal Policy:')\n",
    "if side*side == nS:\n",
    "    grid = np.array([arrow_map[a] for a in pi_opt]).reshape(side, side)\n",
    "    for r in range(side): print(' '.join(grid[r]))\n",
    "else: print(pi_opt)\n",
    "\n",
    "# Keep window responsive briefly\n",
    "try:\n",
    "    import pygame\n",
    "    for _ in range(80):\n",
    "        pygame.event.pump(); time.sleep(0.03)\n",
    "except Exception:\n",
    "    time.sleep(2.0)\n",
    "env.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0",
   "mimetype": "text/x-python",
   "file_extension": ".py",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
